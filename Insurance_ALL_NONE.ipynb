{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa876f2",
   "metadata": {},
   "source": [
    "# Basic data import and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b535bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic data import and pre-processing\n",
    "# Imports\n",
    "\n",
    "import glob\n",
    "import string\n",
    "import ast\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz \n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Insurance_Fraud from your computer, you need to change your source...\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel (r'/Users/sunqiaoyubing/Downloads/I_Fraud.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "import category_encoders as ce\n",
    "encoder = ce.OrdinalEncoder(cols=['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'Sex',\n",
    "             'Month', 'DayOfWeek', 'Make', 'AccidentArea', 'Month', 'DayOfWeek', 'Make', 'MaritalStatus',\n",
    "             'Fault', 'PolicyType', 'VehicleCategory','VehiclePrice', 'Days_Policy_Accident', 'Days_Policy_Claim',\n",
    "             'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder','PoliceReportFiled', 'WitnessPresent',\n",
    "             'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars','BasePolicy'])\n",
    "\n",
    "\n",
    "df = encoder.fit_transform(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df.drop(['FraudFound_P'], axis=1)\n",
    "y_all = df['FraudFound_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4529214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split to test&train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=25\n",
    ")\n",
    "\n",
    "print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n",
    "% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bc888",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811c986",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e72c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistics regression without penalty\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a84b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg = LogisticRegression(penalty='l2')\n",
    "logreg = LogisticRegression(penalty='l2',C= 0.01)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: Logistic Regreesion model for Fraud Detection ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n",
    "% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import recall_score\n",
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e46683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8397c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(logreg, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1dea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f882d3",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9943b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=5)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Tree Model\n",
    "plt.figure(figsize=(16,13))\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "y_pred = clf_gini.predict(X_test)\n",
    "tree.plot_tree(clf_gini.fit(X_train,y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e353c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate: Confusion Matrix\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "y_score = clf_gini.predict_proba(X_test)[:, 1]\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01de295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(clf_gini, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606131d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "y_pred = rf.predict(X_test)\n",
    "print (y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66243360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "y_score = rf.predict_proba(X_test)[:, 1]\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedd83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(rf, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7cdb73",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3528817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf')\n",
    "clf_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_svm.predict(X_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf_svm.decision_function(X_test)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078630be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c74980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bf1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(clf_svm, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1e2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
