{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code and restart the kernal, then start from next code box\n",
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2b5b4",
   "metadata": {},
   "source": [
    "## Basic data import and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import glob\n",
    "import string\n",
    "import ast\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz \n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c71252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CC_Fraud from your computer, you need to change your source...\n",
    "\n",
    "df = pd.read_csv (r'/Users/sunqiaoyubing/Downloads/CC_Fraud.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature SET-2 Data\n",
    "feature2=['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']\n",
    "\n",
    "from pandas import DataFrame\n",
    "X_all = df[feature2]\n",
    "y_all = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca303d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split to test&train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=25\n",
    ")\n",
    "\n",
    "print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n",
    "% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Apply SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=25)\n",
    "\n",
    "X_sm, y_sm = sm.fit_resample(X_all, y_all)\n",
    "\n",
    "print(f'''Shape of X before SMOTE: {X_all.shape}\n",
    "Shape of X after SMOTE: {X_sm.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "y_sm.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sm, y_sm, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c8144",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efba415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistics regression without penalty\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c561400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc5d5d",
   "metadata": {},
   "source": [
    "Pay attention: here next one need to customized to best model with parameter previous box comes out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg = LogisticRegression(penalty='l2')\n",
    "logreg = LogisticRegression(penalty='l2',C= 0.01)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1df05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: Logistic Regreesion model for Fraud Detection ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f97a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n",
    "% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import recall_score\n",
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc90b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(logreg, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec973f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac2dd23",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "# defining parameter range\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58548529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6ee32",
   "metadata": {},
   "source": [
    "Pay attention: here next one need to customized to best model with parameter previous box comes out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf',C=10, gamma=0.01)\n",
    "clf_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_svm.predict(X_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf_svm.decision_function(X_test)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a77de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(clf_svm, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c61ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
