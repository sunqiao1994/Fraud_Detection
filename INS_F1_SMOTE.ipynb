{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a202582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code and restart the kernal, then start from next code box\n",
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f2aaa",
   "metadata": {},
   "source": [
    "## Basic data import and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585fd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import glob\n",
    "import string\n",
    "import ast\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz \n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e656e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Insurance_Fraud from your computer, you need to change your source...\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel (r'/Users/sunqiaoyubing/Downloads/I_Fraud.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "import category_encoders as ce\n",
    "encoder = ce.OrdinalEncoder(cols=['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'Sex',\n",
    "             'Month', 'DayOfWeek', 'Make', 'AccidentArea', 'Month', 'DayOfWeek', 'Make', 'MaritalStatus',\n",
    "             'Fault', 'PolicyType', 'VehicleCategory','VehiclePrice', 'Days_Policy_Accident', 'Days_Policy_Claim',\n",
    "             'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder','PoliceReportFiled', 'WitnessPresent',\n",
    "             'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars','BasePolicy'])\n",
    "\n",
    "\n",
    "df = encoder.fit_transform(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57464d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature SET-1\n",
    "feature1=['Fault','PolicyType','VehicleCategory','PastNumberOfClaims','BasePolicy','DayOfWeekClaimed','MonthClaimed','Age','PolicyNumber','RepNumber']\n",
    " \n",
    "\n",
    "X_all = df[feature1]\n",
    "y_all = df['FraudFound_P']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split to test&train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=25\n",
    ")\n",
    "\n",
    "print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n",
    "% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf21b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Apply SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=25)\n",
    "\n",
    "X_sm, y_sm = sm.fit_resample(X_all, y_all)\n",
    "\n",
    "print(f'''Shape of X before SMOTE: {X_all.shape}\n",
    "Shape of X after SMOTE: {X_sm.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "y_sm.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sm, y_sm, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6c977",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistics regression without penalty\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21376b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcaa36b",
   "metadata": {},
   "source": [
    "Pay attention: here next one need to customized to best model with parameter previous box comes out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg = LogisticRegression(penalty='l2')\n",
    "logreg = LogisticRegression(penalty='l2',C= 0.01)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fe0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b460662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve: Logistic Regreesion model for Fraud Detection ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4952e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n",
    "% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import recall_score\n",
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c740b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e13559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(logreg, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879a36d",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e32687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "# defining parameter range\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50571f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900586b1",
   "metadata": {},
   "source": [
    "Pay attention: here next one need to customized to best model with parameter previous box comes out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f847974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf',C=10, gamma=0.01)\n",
    "clf_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_svm.predict(X_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf_svm.decision_function(X_test)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}\\nRecall = {recall_score(y_test, y_pred):.2f}\\n')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix (without Resampling)', size=16)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e35a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision score\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot precision - recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "auc_precision_recall = auc(recall, precision)\n",
    "print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUPRC\n",
    "disp = plot_precision_recall_curve(clf_svm, X_test, y_test)\n",
    "disp.ax_.set_title('Binary class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
